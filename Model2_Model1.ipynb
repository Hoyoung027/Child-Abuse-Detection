{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder_path) : # jpg 파일 목록 반환\n",
    "    file_list_all = os.listdir(folder_path)\n",
    "    file_list = [file for file in file_list_all if file.endswith('jpg')]\n",
    "    return file_list\n",
    "\n",
    "# 각 sequece에서 원하는 만큼의 이미지를 추출\n",
    "def data_maker(all_images, n) :\n",
    "\n",
    "    selected_images = []\n",
    "    if n == 7 :\n",
    "        selected_images = all_images\n",
    "\n",
    "    else :\n",
    "        # 7장의 이미지 중 가운데 n장만 선택\n",
    "        for i in range(0, len(all_images), 7):\n",
    "            \n",
    "            start = i + int((7 - n) / 2)\n",
    "            end = i + int((7 + n) / 2)\n",
    "           \n",
    "            selected_images.extend(all_images[start:end])\n",
    "\n",
    "    images = [image.load_img(p, target_size=(224, 224)) for p in selected_images]\n",
    "    vector = np.asarray([image.img_to_array(img) for img in images])\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "1256\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 경로\n",
    "\n",
    "test_CA_Y_folder = read_folder(\"./test/image/CA_Y\")\n",
    "test_CA_N_folder = read_folder(\"./test/image/CA_N\")\n",
    "# test_CA_Y_folder = read_folder(\"./temp_test/CA_Y\")\n",
    "# test_CA_N_folder = read_folder(\"./temp_test/CA_N\")\n",
    "\n",
    "train_CA_Y_folder = read_folder(\"./train/image/CA_Y\")\n",
    "train_CA_N_folder = read_folder(\"./train/image/CA_N\")\n",
    "# train_CA_Y_folder = read_folder(\"./temp_train/CA_Y\")\n",
    "# train_CA_N_folder = read_folder(\"./temp_train/CA_N\")\n",
    "\n",
    "# 학대 => 1, 학대 x => 0으로  라벨링데이터 생성\n",
    "# labels = ([1] * int(len(CA_Y_folder)/7)) + ([0] * int(len(CA_N_folder)/7))\n",
    "# print(len(labels))\n",
    "test_label = ([1] * int(len(test_CA_Y_folder)/7)) + ([0] * int(len(test_CA_N_folder)/7))\n",
    "train_label = ([1] * int(len(train_CA_Y_folder)/7)) + ([0] * int(len(train_CA_N_folder)/7))\n",
    "print(len(test_label))\n",
    "print(len(train_label))\n",
    "\n",
    "# 전체 이미지 데이터 불러오기\n",
    "# all_images = glob('./CA_Y/*jpg') + glob('./CA_N/*jpg')\n",
    "\n",
    "\n",
    "# test_images = glob('./temp_test/CA_Y/*jpg') + glob('./temp_test/CA_N/*jpg')\n",
    "# train_images = glob('./temp_train/CA_Y/*jpg') + glob('./temp_train/CA_N/*jpg')\n",
    "test_images = glob('./test/image/CA_Y/*jpg') + glob('./test/image/CA_N/*jpg')\n",
    "train_images = glob('./train/image/CA_Y/*jpg') + glob('./train/image/CA_N/*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.load_model(\"model1_layer3_RMSprop_simple.keras\")\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('flatten_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │      \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> (18.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,719,616\u001b[0m (18.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,995,072</span> (38.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,995,072\u001b[0m (38.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_per_sequence = 1\n",
    "# vector = data_maker(all_images, image_per_sequence)\n",
    "# vector.shape\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "# 개별 이미지에서 벡터를 추출\n",
    "# vectors = model.predict(preprocess_input(vector)) \n",
    "\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 25088)\n",
      "(1256, 25088)\n"
     ]
    }
   ],
   "source": [
    "# vectors.shape\n",
    "\n",
    "print(test_vectors.shape)\n",
    "print(train_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_concatenated_vectors : (165, 25088)\n",
      "train_concatenated_vectors : (1256, 25088)\n"
     ]
    }
   ],
   "source": [
    "# concatenated_vectors = np.array([])\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "# concatenated_vectors = concatenate_vectors(vectors, image_per_sequence)\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "    \n",
    "# 결과 출력\n",
    "# print(concatenated_vectors.shape)  \n",
    "print(f\"test_concatenated_vectors : {test_concatenated_vectors.shape}\")  \n",
    "print(f\"train_concatenated_vectors : {train_concatenated_vectors.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split  \n",
    "# X_train, X_test, y_train, y_test = train_test_split(concatenated_vectors, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "# 랜덤한 인덱스를 생성\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "# 인덱스를 사용하여 배열을 섞음\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "print(train_shuffled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151515151515152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model2_Seq1_Model1.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_Model1.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step\n",
      "0.7151515151515152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq3_Model1.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 3\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_Model1.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 2s/step\n",
      "0.7151515151515152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq5_Model1.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 5\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_Model1.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 2s/step\n",
      "0.7212121212121212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq7_Model1.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 7\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_Model1.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
