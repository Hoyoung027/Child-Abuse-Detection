{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_extract_frame(video_name, video_path, output_path, frame_rate, s_list) :\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"auto_extract_frame에서 비디오 파일을 열 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # FPS(Frame Per Second) 정보 가져오기\n",
    "    fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    for i in range(len(s_list)) : # 접촉 시점마다 전후 1초동안 7장의 이미지를 추출\n",
    "\n",
    "        start_time = s_list[i]\n",
    "        interval = 2\n",
    "\n",
    "        # 원하는 시간의 프레임 번호 계산\n",
    "        frame_number = int((start_time- 1) * fps)\n",
    "        end_frame_number = frame_number + interval * fps + 1\n",
    "        \n",
    "        while(frame_number <= end_frame_number) :\n",
    "             \n",
    "            # 해당 프레임으로 위치 설정\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    \n",
    "            # 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            if ret:\n",
    "                # 프레임을 이미지 파일로 저장\n",
    "                image_output_path = f\"{output_path}/{video_name[:-4]}_startTime{start_time}_{frame_number}.jpg\"\n",
    "                cv2.imwrite(image_output_path, frame)\n",
    "            else:\n",
    "                print(\"프레임을 읽을 수 없습니다.\")\n",
    "                break\n",
    "            \n",
    "            frame_number += int(fps / frame_rate)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    # 비디오 캡처 객체 해제\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def touch_detection(video_name, video_path, output_path, start_time, frame_rate, model_path):\n",
    "\n",
    "    print(f\"{video_name}, 접촉 여부 판정이 시작되었습니다\")\n",
    "    \n",
    "    # 모형 불러오기\n",
    "    model = models.load_model(model_path) # model 불러오기\n",
    "\n",
    "    # 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"touch_detection에서 비디오 파일을 열 수 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # FPS(Frame Per Second) 정보 가져오기\n",
    "    fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    if fps == 0:\n",
    "        print(\"FPS 정보를 가져올 수 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 원하는 시간의 프레임 번호 계산\n",
    "    frame_number = int(start_time * fps)\n",
    "    \n",
    "    # frame_list = []\n",
    "    touch_time = []\n",
    "    while(True) : #동영상 끝까지 이미지를 추출\n",
    "        \n",
    "        # 해당 프레임으로 위치 설정\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        # 프레임 읽기\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        if ret:\n",
    "            # 프레임을 이미지 파일로 저장\n",
    "            print(output_path)\n",
    "            image_output_path = f\"{output_path}/{video_name[:-4]}_{int(frame_number / fps)}.jpg\"\n",
    "            cv2.imwrite(image_output_path, frame)\n",
    "\n",
    "            # 이미지 가공\n",
    "            IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "            img = Image.open(image_output_path)\n",
    "            img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "            np_img = image.img_to_array(img)\n",
    "            img_batch = np.expand_dims(np_img, axis=0) #이미지 4차원으로 변형\n",
    "            pre_processed = preprocess_input(img_batch) # nomalization\n",
    "\n",
    "            # 모형을 통한 이미지의 접촉 여부 예측\n",
    "            y_preds = model.predict(pre_processed)\n",
    "\n",
    "            # 접촉 여부 확률에 따른 접촉 시간 저장\n",
    "            if(y_preds[0][1] > 0.6) :\n",
    "\n",
    "                end_frame_number = frame_number + fps \n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, end_frame_number)\n",
    "                ret, frame = cap.read()\n",
    "                if ret != True :\n",
    "                    os.remove(image_output_path)\n",
    "                    break\n",
    "                \n",
    "                touch_time.append(int(frame_number / fps))\n",
    "                # frame_list.append(frame_number)\n",
    "                \n",
    "                print(f\"{int(frame_number / fps)}초에 접촉이 감지되었습니다.\")\n",
    "                print(\"접촉 일어났을 확률 :\", y_preds[0][1])\n",
    "            else :\n",
    "                os.remove(image_output_path)\n",
    "        else:\n",
    "            print(\"프레임을 읽을 수 없습니다.\")\n",
    "            break\n",
    "\n",
    "        frame_number += int(fps / frame_rate)\n",
    "    \n",
    "    # 비디오 캡처 객체 해제\n",
    "    cap.release()\n",
    "    return touch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_image(video_name, video_path) :\n",
    "    \n",
    "    model_path = \"./model0_VGG16_layer5_RMSprop.keras\"\n",
    "    \n",
    "    frame_rate_check_touch = 1  # 1초당 1장을 저장\n",
    "    frame_rate_check_child_abuse = 3  # 1초당 3장\n",
    "    \n",
    "    output_path_check_touch = \"./check_touch\"\n",
    "    output_path_check_child_abuse = \"./check_child_abuse\"\n",
    "    start_time = 1\n",
    "    \n",
    "    # video_name = \"test_video.mp4\"\n",
    "    # video_path = video_folder_path + \"/\" + video_name\n",
    "        \n",
    "    touch_times = touch_detection(video_name, video_path, output_path_check_touch, start_time, frame_rate_check_touch, model_path)\n",
    "    print(touch_times)\n",
    "    auto_extract_frame(video_name, video_path, output_path_check_child_abuse, frame_rate_check_child_abuse, touch_times)\n",
    "        \n",
    "    print(\"\")\n",
    "    print(f\"{video_name}번째 영상에 대한 학대 의심 장면 추출이 완료되었습니다.\")\n",
    "    print(\"\")\n",
    "\n",
    "    return touch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 sequece에서 원하는 만큼의 이미지를 추출\n",
    "def data_maker(all_images, n) :\n",
    "\n",
    "    selected_images = []\n",
    "    if n == 7 :\n",
    "        selected_images = all_images\n",
    "\n",
    "    else :\n",
    "        # 7장의 이미지 중 가운데 n장만 선택\n",
    "        for i in range(0, len(all_images), 7):\n",
    "            \n",
    "            start = i + int((7 - n) / 2)\n",
    "            end = i + int((7 + n) / 2)\n",
    "           \n",
    "            selected_images.extend(all_images[start:end])\n",
    "\n",
    "    images = [image.load_img(p, target_size=(224, 224)) for p in selected_images]\n",
    "    vector = np.asarray([image.img_to_array(img) for img in images])\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_images_in_folder(folder_path):\n",
    "    # 이미지 파일 경로 리스트 가져오기\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            os.remove(os.path.join(folder_path, image_file))\n",
    "            # print(f\"Deleted {image_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import joblib\n",
    "import shutil\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# check_times = len(touch_times)\n",
    "\n",
    "def child_abuse_detection(video_name) :\n",
    "\n",
    "    video_path = \"./\" + video_name\n",
    "    touch_times = video_to_image(video_name, video_path)\n",
    "\n",
    "    all_images = glob('./check_child_abuse/*jpg')\n",
    "    \n",
    "    images = all_images\n",
    "    image_per_sequence = 3\n",
    "\n",
    "    base_model = VGG16(weights='imagenet', include_top=True)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "    \n",
    "    vector = data_maker(images, image_per_sequence)\n",
    "    vectors = model.predict(preprocess_input(vector))\n",
    "    \n",
    "    \n",
    "    def concatenate_vectors(vectors, n):\n",
    "        concatenated_vectors = []\n",
    "        for i in range(0, vectors.shape[0], n):\n",
    "            concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "            concatenated_vectors.append(concatenated)\n",
    "        return np.vstack(concatenated_vectors)\n",
    "    \n",
    "    # 함수 호출\n",
    "    concatenated_vectors = concatenate_vectors(vectors, image_per_sequence)\n",
    "    \n",
    "    # print(concatenated_vectors.shape)\n",
    "    model2 = joblib.load('Model2_Seq3_VGG16.joblib')\n",
    "    \n",
    "    # 불러온 모델로 예측, 0 -> 학대X / 1 -> 학대O\n",
    "    predictions = model2.predict(concatenated_vectors)\n",
    "    # print(predictions)\n",
    "\n",
    "    # 예측 결과에 따라 파일 이동\n",
    "    output_folder = \"./child_abuse_confirmed\"\n",
    "\n",
    "    ca_time = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1:\n",
    "            \n",
    "            ca_time.append(touch_times[i])\n",
    "            \n",
    "            # 이동할 이미지 선택\n",
    "            print(f\"{video_name}의 {touch_times[i]}초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\")\n",
    "            start_index = 7 * i\n",
    "            end_index = start_index + 7\n",
    "            selected_images = images[start_index:end_index]\n",
    "            \n",
    "            for image in selected_images:\n",
    "                # 파일 이동\n",
    "                shutil.move(image, os.path.join(output_folder, os.path.basename(image)))\n",
    "                # print(f\"Moved {image} to {output_folder}\")\n",
    "\n",
    "    if(len(ca_time) == 0) :\n",
    "        print(\"학대 의심 행동이 발견되지 않았습니다\")\n",
    "    else :\n",
    "        print(\"\")\n",
    "        print(f\"총 {len(ca_time)}건의 학대 의심 행동이 발견되었습니다\")\n",
    "        print(f\"영상 내 학대 발견된 지점(s) : {ca_time}\")\n",
    "        print(\"\")\n",
    "\n",
    "    delete_all_images_in_folder(\"./check_child_abuse\")\n",
    "    delete_all_images_in_folder(\"./check_touch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_video1.mp4, 접촉 여부 판정이 시작되었습니다\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "1초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.6245402\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "9초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.71140313\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "10초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.66036457\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "18초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.8635177\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "[1, 9, 10, 18]\n",
      "\n",
      "test_video1.mp4번째 영상에 대한 학대 의심 장면 추출이 완료되었습니다.\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "학대 의심 행동이 발견되지 않았습니다\n"
     ]
    }
   ],
   "source": [
    "child_abuse_detection(\"test_video1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_video2.mp4, 접촉 여부 판정이 시작되었습니다\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "40초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.89934856\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "프레임을 읽을 수 없습니다.\n",
      "[40]\n",
      "\n",
      "test_video2.mp4번째 영상에 대한 학대 의심 장면 추출이 완료되었습니다.\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "test_video2.mp4의 40초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "\n",
      "총 1건의 학대 의심 행동이 발견되었습니다\n",
      "영상 내 학대 발견된 지점(s) : [40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "child_abuse_detection(\"test_video2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_video3.mp4, 접촉 여부 판정이 시작되었습니다\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "3초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9974841\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
      "4초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99720746\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "5초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99859494\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "6초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9991135\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "7초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9995995\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "8초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99482006\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "9초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9971365\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "10초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9988739\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "11초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99784935\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
      "12초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.999824\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "13초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99732155\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "14초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.997678\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "15초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9925426\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "16초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9991271\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "17초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9926116\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "18초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9965063\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
      "19초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9960855\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "20초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9438388\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "21초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9991767\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "22초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99587965\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
      "23초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99808866\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "24초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9479115\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "25초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99922657\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "26초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99747664\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "27초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9963813\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "28초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99860257\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "29초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9889552\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "30초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.999843\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "31초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99746263\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "32초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.9964457\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "33초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99774194\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "34초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.99403185\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "35초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.7307043\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "40초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.71325964\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "41초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.74328196\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
      "47초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.7100961\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "52초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.7536474\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "54초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.7424722\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "55초에 접촉이 감지되었습니다.\n",
      "접촉 일어났을 확률 : 0.87264997\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "./check_touch\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
      "프레임을 읽을 수 없습니다.\n",
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 47, 52, 54, 55]\n",
      "\n",
      "test_video3.mp4번째 영상에 대한 학대 의심 장면 추출이 완료되었습니다.\n",
      "\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step\n",
      "test_video3.mp4의 3초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 4초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 5초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 6초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 7초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 8초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 9초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 10초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 11초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 12초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 13초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 14초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 15초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 16초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 17초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 18초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 19초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 20초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 21초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 22초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 23초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 24초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 25초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 26초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 27초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 28초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 29초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 30초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 31초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 32초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 33초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 34초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 35초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 40초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 41초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 47초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 52초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 54초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "test_video3.mp4의 55초에 학대가 의심되는 행동이 감지되어 이미지를 저장합니다\n",
      "\n",
      "총 39건의 학대 의심 행동이 발견되었습니다\n",
      "영상 내 학대 발견된 지점(s) : [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 47, 52, 54, 55]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "child_abuse_detection(\"test_video3.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
