{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder_path) : # jpg 파일 목록 반환\n",
    "    file_list_all = os.listdir(folder_path)\n",
    "    file_list = [file for file in file_list_all if file.endswith('jpg')]\n",
    "    return file_list\n",
    "\n",
    "# 각 sequece에서 원하는 만큼의 이미지를 추출\n",
    "def data_maker(all_images, n) :\n",
    "\n",
    "    selected_images = []\n",
    "    if n == 7 :\n",
    "        selected_images = all_images\n",
    "\n",
    "    else :\n",
    "        # 7장의 이미지 중 가운데 n장만 선택\n",
    "        for i in range(0, len(all_images), 7):\n",
    "            \n",
    "            start = i + int((7 - n) / 2)\n",
    "            end = i + int((7 + n) / 2)\n",
    "           \n",
    "            selected_images.extend(all_images[start:end])\n",
    "\n",
    "    images = [image.load_img(p, target_size=(224, 224)) for p in selected_images]\n",
    "    vector = np.asarray([image.img_to_array(img) for img in images])\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "1256\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 경로\n",
    "\n",
    "test_CA_Y_folder = read_folder(\"./test/image/CA_Y\")\n",
    "test_CA_N_folder = read_folder(\"./test/image/CA_N\")\n",
    "# test_CA_Y_folder = read_folder(\"./temp_test/CA_Y\")\n",
    "# test_CA_N_folder = read_folder(\"./temp_test/CA_N\")\n",
    "\n",
    "train_CA_Y_folder = read_folder(\"./train/image/CA_Y\")\n",
    "train_CA_N_folder = read_folder(\"./train/image/CA_N\")\n",
    "# train_CA_Y_folder = read_folder(\"./temp_train/CA_Y\")\n",
    "# train_CA_N_folder = read_folder(\"./temp_train/CA_N\")\n",
    "\n",
    "# 학대 => 1, 학대 x => 0으로  라벨링데이터 생성\n",
    "# labels = ([1] * int(len(CA_Y_folder)/7)) + ([0] * int(len(CA_N_folder)/7))\n",
    "# print(len(labels))\n",
    "test_label = ([1] * int(len(test_CA_Y_folder)/7)) + ([0] * int(len(test_CA_N_folder)/7))\n",
    "train_label = ([1] * int(len(train_CA_Y_folder)/7)) + ([0] * int(len(train_CA_N_folder)/7))\n",
    "print(len(test_label))\n",
    "print(len(train_label))\n",
    "\n",
    "# 전체 이미지 데이터 불러오기\n",
    "# all_images = glob('./CA_Y/*jpg') + glob('./CA_N/*jpg')\n",
    "\n",
    "\n",
    "# test_images = glob('./temp_test/CA_Y/*jpg') + glob('./temp_test/CA_N/*jpg')\n",
    "# train_images = glob('./temp_train/CA_Y/*jpg') + glob('./temp_train/CA_N/*jpg')\n",
    "test_images = glob('./test/image/CA_Y/*jpg') + glob('./test/image/CA_N/*jpg')\n",
    "train_images = glob('./train/image/CA_Y/*jpg') + glob('./train/image/CA_N/*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=True)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │     \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_per_sequence = 1\n",
    "# vector = data_maker(all_images, image_per_sequence)\n",
    "# vector.shape\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "# 개별 이미지에서 벡터를 추출\n",
    "# vectors = model.predict(preprocess_input(vector)) \n",
    "\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 4096)\n",
      "(1256, 4096)\n"
     ]
    }
   ],
   "source": [
    "# vectors.shape\n",
    "\n",
    "print(test_vectors.shape)\n",
    "print(train_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_concatenated_vectors : (165, 4096)\n",
      "train_concatenated_vectors : (1256, 4096)\n"
     ]
    }
   ],
   "source": [
    "# concatenated_vectors = np.array([])\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "# concatenated_vectors = concatenate_vectors(vectors, image_per_sequence)\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "    \n",
    "# 결과 출력\n",
    "# print(concatenated_vectors.shape)  \n",
    "print(f\"test_concatenated_vectors : {test_concatenated_vectors.shape}\")  \n",
    "print(f\"train_concatenated_vectors : {train_concatenated_vectors.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split  \n",
    "# X_train, X_test, y_train, y_test = train_test_split(concatenated_vectors, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "# 랜덤한 인덱스를 생성\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "# 인덱스를 사용하여 배열을 섞음\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "print(train_shuffled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model2_Seq1_VGG16.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_VGG16.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vector : (495, 224, 224, 3)\n",
      "train_vector : (3768, 224, 224, 3)\n",
      "\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 4s/step\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 3s/step\n",
      "test_vectors : (495, 224, 224, 3)\n",
      "train_vectors : (3768, 224, 224, 3)\n",
      "\n",
      "test_concatenated_vectors : (165, 12288)\n",
      "train_concatenated_vectors : (1256, 12288)\n",
      "\n",
      "0.9393939393939394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq3_VGG16.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 3\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "print(f\"test_vector : {test_vector.shape}\")  \n",
    "print(f\"train_vector : {train_vector.shape}\")  \n",
    "print(\"\")\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "print(f\"test_vectors : {test_vector.shape}\")  \n",
    "print(f\"train_vectors : {train_vector.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "print(f\"test_concatenated_vectors : {test_concatenated_vectors.shape}\")  \n",
    "print(f\"train_concatenated_vectors : {train_concatenated_vectors.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_VGG16.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vector : (825, 224, 224, 3)\n",
      "train_vector : (6280, 224, 224, 3)\n",
      "\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 4s/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 3s/step\n",
      "test_vectors : (825, 224, 224, 3)\n",
      "train_vectors : (6280, 224, 224, 3)\n",
      "\n",
      "test_concatenated_vectors : (165, 20480)\n",
      "train_concatenated_vectors : (1256, 20480)\n",
      "\n",
      "0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq5_VGG16.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 5\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "print(f\"test_vector : {test_vector.shape}\")  \n",
    "print(f\"train_vector : {train_vector.shape}\")  \n",
    "print(\"\")\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "print(f\"test_vectors : {test_vector.shape}\")  \n",
    "print(f\"train_vectors : {train_vector.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "print(f\"test_concatenated_vectors : {test_concatenated_vectors.shape}\")  \n",
    "print(f\"train_concatenated_vectors : {train_concatenated_vectors.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_VGG16.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vector : (1155, 224, 224, 3)\n",
      "train_vector : (8792, 224, 224, 3)\n",
      "\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 3s/step\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 2s/step\n",
      "test_vectors : (1155, 224, 224, 3)\n",
      "train_vectors : (8792, 224, 224, 3)\n",
      "\n",
      "test_concatenated_vectors : (165, 28672)\n",
      "train_concatenated_vectors : (1256, 28672)\n",
      "\n",
      "0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model2_Seq7_VGG16.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "image_per_sequence = 7\n",
    "\n",
    "test_vector = data_maker(test_images, image_per_sequence)\n",
    "train_vector = data_maker(train_images, image_per_sequence)\n",
    "print(f\"test_vector : {test_vector.shape}\")  \n",
    "print(f\"train_vector : {train_vector.shape}\")  \n",
    "print(\"\")\n",
    "\n",
    "# 개별 이미지에서 벡터를 추출\n",
    "test_vectors = model.predict(preprocess_input(test_vector))\n",
    "train_vectors = model.predict(preprocess_input(train_vector))\n",
    "print(f\"test_vectors : {test_vector.shape}\")  \n",
    "print(f\"train_vectors : {train_vector.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "# concatenation\n",
    "test_concatenated_vectors = np.array([])\n",
    "train_concatenated_vectors = np.array([])\n",
    "\n",
    "# (이미지 수, 4096) 형태의 배열을 n개씩 묶어서 (이미지수 / n, 4096 * n) 벡터를 만드는 함수\n",
    "def concatenate_vectors(vectors, n):\n",
    "    concatenated_vectors = []\n",
    "    for i in range(0, vectors.shape[0], n):\n",
    "        concatenated = vectors[i:i+n].reshape(1, -1)\n",
    "        concatenated_vectors.append(concatenated)\n",
    "    return np.vstack(concatenated_vectors)\n",
    "\n",
    "# 함수 호출\n",
    "test_concatenated_vectors = concatenate_vectors(test_vectors, image_per_sequence)\n",
    "train_concatenated_vectors = concatenate_vectors(train_vectors, image_per_sequence)\n",
    "print(f\"test_concatenated_vectors : {test_concatenated_vectors.shape}\")  \n",
    "print(f\"train_concatenated_vectors : {train_concatenated_vectors.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# 데이터 shuffling\n",
    "test_label = np.array(test_label)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "test_indices = np.random.permutation(len(test_concatenated_vectors))\n",
    "train_indices = np.random.permutation(len(train_concatenated_vectors))\n",
    "\n",
    "test_concatenated_shuffled_vectors = test_concatenated_vectors[test_indices]\n",
    "test_shuffled_label = test_label[test_indices]\n",
    "\n",
    "train_concatenated_shuffled_vectors = train_concatenated_vectors[train_indices]\n",
    "train_shuffled_label = train_label[train_indices]\n",
    "\n",
    "\n",
    "# 로지스틱 회귀모형 학습 \n",
    "lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_p1.fit(train_concatenated_shuffled_vectors, train_shuffled_label)\n",
    "print(lr_p1.score(test_concatenated_shuffled_vectors, test_shuffled_label))\n",
    "\n",
    "# 모형 저장하기\n",
    "model_name = f\"Model2_Seq{image_per_sequence}_VGG16.joblib\"\n",
    "joblib.dump(lr_p1, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 사용하기\n",
    "# loaded_model = joblib.load('Model2.joblib')\n",
    "\n",
    "# 불러온 모델로 예측\n",
    "# predictions = loaded_model.predict(X_test)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import log_loss\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할\n",
    "#X_train, X_test, y_train, y_test = train_test_split(concatenated_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 초기화\n",
    "#lr_p1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=1, warm_start=True)\n",
    "\n",
    "# 손실 값 저장 리스트 초기화\n",
    "#train_losses = []\n",
    "#val_losses = []\n",
    "\n",
    "# 반복 학습\n",
    "#for i in range(10000):  # 10000번의 반복 학습\n",
    "#    lr_p1.fit(X_train, y_train)\n",
    "    \n",
    "    # 훈련 손실 계산\n",
    "#    y_train_pred_prob = lr_p1.predict_proba(X_train)\n",
    "#    train_loss = log_loss(y_train, y_train_pred_prob)\n",
    "#    train_losses.append(train_loss)\n",
    "    \n",
    "    # 검증 손실 계산\n",
    "#    y_val_pred_prob = lr_p1.predict_proba(X_test)\n",
    "#    val_loss = log_loss(y_test, y_val_pred_prob)\n",
    "#    val_losses.append(val_loss)\n",
    "\n",
    "# 손실 함수 시각화\n",
    "#epochs = range(1, 10001)  # 100번의 반복 학습\n",
    "#plt.plot(epochs, train_losses, 'bo-', label='loss')\n",
    "#plt.plot(epochs, val_losses, 'ro-', label='val_loss')\n",
    "#plt.title('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.ylabel('loss')\n",
    "#plt.legend()\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
